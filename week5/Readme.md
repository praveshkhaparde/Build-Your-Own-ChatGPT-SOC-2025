## Week 5: Transformers for NLP

In this and the upcoming week, weâ€™ll dive into **Transformers** â€” deep learning models designed to process sequential data efficiently. These models are at the core of many advanced NLP tasks such as **translation**, **summarization**, and **text generation**.

---

###  Learning Resources

- ðŸ“º [Full Transformers Playlist (3Blue1Brown-style)](https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&si=1gNFWJGoxTsf6FSB)  
  A visually intuitive series that explains attention and transformers in depth.

- [Transformers from Scratch (Jay Alammar)](https://youtu.be/QEaBAZQCtwE?si=mXfUy9GO5dQf_pVJ)  
- [BERT Explained Visually](https://youtu.be/zxQyTK8quyY?si=7AD_1ex-nt17t60M)  

---

## Milestone 3: Sentiment Analysis using Transformer Embeddings

> **Note**: You are **not** expected to fine-tune transformer models â€” use them only for generating embeddings.

### ðŸŽ¯ Task:

- Build a **Sentiment Analysis Model** using **transformer-based embeddings**
- **Goal**: Classify movie reviews as **positive** or **negative**
- You can use any transformer model (e.g., BERT, DistilBERT) to extract embeddings
- If you've completed **Milestone 2**, you just need to update the embedding part â€” minimal code change required

---

Let me know if you want to add Hugging Face links, dataset references, or starter code for embedding extraction!
